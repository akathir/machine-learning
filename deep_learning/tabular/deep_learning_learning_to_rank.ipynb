{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8727ab9d-ef7a-4ac5-b871-d2445f6f6aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading notebook's format\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "from formats import load_style\n",
    "load_style(css_style='custom2.css', plot_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a2aa51-3834-4c0b-9290-56a5ddfab1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Last updated: 2023-09-06 04:00:55\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.6\n",
      "IPython version      : 8.13.2\n",
      "\n",
      "torch       : 2.0.1\n",
      "sklearn     : 1.3.0\n",
      "numpy       : 1.23.2\n",
      "pandas      : 2.0.1\n",
      "torchmetrics: 1.0.3\n",
      "datasets    : 2.14.4\n",
      "transformers: 4.31.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import functional as F\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    PreTrainedModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torchmetrics\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -u -p torch,sklearn,numpy,pandas,torchmetrics,datasets,transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1811fb70-f177-4958-9198-0b4903896e1a",
   "metadata": {},
   "source": [
    "# Learning to Rank 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38980a12-b354-4da6-9cdf-4febdc8c4718",
   "metadata": {},
   "source": [
    "Suppose we have a query denoted as $q$, and its corresponding $n$ set of documents denoted as $D = {d_1, d_2, ..., d_n}$. Our objective is to learn a function $f$ such that $f(q, D)$ will produce an ordered collection of documents, $D^*$, in descending order of relevance. Where the exact definition of relevance can vary between different applications.\n",
    "\n",
    "In general, there're three main types of loss function for training this function: pointwise, pairwise, listwise. In this article, we'll be giving a 101 introduction to each of these variants, list out their pros and cons, as well as implementing these loss functions ourselves and training the tabular deep learning module using huggingface Trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa445e6f-eb73-4a54-9730-3ea322ed34be",
   "metadata": {},
   "source": [
    "**Pointwise**\n",
    "\n",
    "For pointwise approach, the aforementioned ranking task is formulated as a classic regression or classification task. The function $f(q, D)$ is simplied to $f(q, d_i)$, treating the relevance assessment of each query document independently. Suppose we have two queries that yield 2 and 3 corresponding documents respectively:\n",
    "\n",
    "\\begin{align}\n",
    "q_1 & \\rightarrow d_1, d_2 \\nonumber \\\\\n",
    "q_2 & \\rightarrow d_3, d_4, d_5\n",
    "\\end{align}\n",
    "\n",
    "The training examples $x_i$ are creating by pairing each query with its associated documents.\n",
    "\n",
    "\\begin{align}\n",
    "x_1: q_1, d_1 \\nonumber \\\\ \n",
    "x_2: q_1, d_2 \\nonumber \\\\\n",
    "x_3: q_2, d_3 \\nonumber \\\\\n",
    "x_4: q_2, d_4 \\nonumber \\\\\n",
    "x_5: q_2, d_5\n",
    "\\end{align}\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Simplicity: Existing machine learning algorithms and loss functions we might be more familiar with can be directly applied in the pointwise setting.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Sub-Optimal Results: This approach may not fully capitalize on the complete information available across the entire document list for a given query, potentially leading to sub-optimal outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3bc012-1eeb-45ca-8c8e-6b159140e4f7",
   "metadata": {},
   "source": [
    "**Pairwise**\n",
    "\n",
    "In pairwise approach, the goal remains identical to pointwise, in which we're learning a pointwise scoring function $f(q, d_i)$, but training instances are constructed using pairs of documents from the same query:\n",
    "\n",
    "\\begin{align}\n",
    "x_1: q_1, (d_1, d_2) \\nonumber \\\\\n",
    "x_2: q_2, (d_3, d_4) \\nonumber \\\\\n",
    "x_3: q_2, (d_3, d_5) \\nonumber \\\\\n",
    "x_4: q_2, (d_4, d_5)\n",
    "\\end{align}\n",
    "\n",
    "This approach introduces a new set of binary pairwise labels, derived by comparing individual relevance scores within each pair. For instance, considering the first query $q_1$, if $y_1 = 0$ (totally irrelevant) for $d_1$ and $y_2 = 3$ (highly relevant) for $d_2$, a new label $y_1 < y_2$ is assigned to the document pair $(d_1, d_2)$. This transforms the task into a binary classification learning problem.\n",
    "\n",
    "To learn the pointwise function $f(q, d_i)$ in a pairwise manner, RankNet [[1]](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf) proposed modeling the score difference probabilistically using logistic function:\n",
    "\n",
    "\\begin{align}\n",
    "Pr(i \\succ j) = \\frac{1}{1 + exp^{-(s_i - s_j)}}\n",
    "\\end{align}\n",
    " \n",
    "Where if document $i$ is deemed a better match than document $j$ ($i \\succ j$), the probability of the scoring function assigning a higher score to $f(q, d_i) = s_i$ than $f(q, d_j) = s_j$ should be close to 1. This reflects the model's effort to understand how to score document pairs based on query information, effectively learning to rank.\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Pairwise Ranking Learning: Compared with pointwise model, pairwise model learns how to rank in a pairwise context, by focusing on correct classification of ordered pairs, it is potentially approximating the ultimate ranking task involving a list of documents.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Pointwise Scoring: The scoring function remains pointwise, implying relative information among different documents with the same query is not yet fully harnessed.\n",
    "- Uneven pairs: If not careful with data curation where the number of documents varies largely from query to query, then the trained model may be biased towards queries with more document pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e10477-1763-4c77-9af7-58a05cc9cf3a",
   "metadata": {},
   "source": [
    "**Listwise**\n",
    "\n",
    "\n",
    "Listwise approach addresses the ranking problem in its natural form, specifically it takes in a list of instances during training so the group structure is maintained.\n",
    "\n",
    "\\begin{align}\n",
    "x_1&: q_1, (d_1, d_2) \\nonumber \\\\ \n",
    "x_2&: q_2, (d_3, d_4, d_5)\n",
    "\\end{align}\n",
    "\n",
    "One of the first proposed approach is ListNet [[2]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf), where the loss is calculated between a predicted probability distribution versus target probability distribution.\n",
    "\n",
    "\\begin{align}\n",
    "P_{\\boldsymbol{y}}\\left(x_i\\right)=\\frac{y_i}{\\sum_{j=1}^n y_j} \\\\\n",
    "P_f\\left(x_i\\right)=\\frac{e^{f(\\boldsymbol{x_i})}}{\\sum_{j=1}^n e^{f(\\boldsymbol{x_j})}}\n",
    "\\end{align}\n",
    "\n",
    "Where:\n",
    "\n",
    "- $x_i$ denotes features representing a particular query-document pair.\n",
    "- $y_i$ represents each document's non-negative relevance labels.\n",
    "- $P_f\\left(x_i\\right)$ encodes the probability of $x_i$ appearing at the top of the ranked list, referred to as top one probability. Given these two distributions, their loss is can be measured by a standard cross entropy loss.\n",
    "\n",
    "\\begin{align}\n",
    "\\ell(\\boldsymbol{y}, f(\\boldsymbol{x})) = -\\sum_{i=1}^n P_{\\boldsymbol{y}}\\left(x_i\\right) \\log P_f\\left(x_i\\right)\n",
    "\\end{align}\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Direct Ranking Learning. By formulating the problem in its native form instead of relying on proxies, it is a theoretically sound solution to approach a ranking task. i.e. Minimizing the errors in ranking the entire document list as opposed to document pairs.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Pointwise Scoring. Scoring function is still pointwise, which could be sub-optimal.\n",
    "\n",
    "Note that:\n",
    "\n",
    "- Different from pointwise approach that also uses softmax function and cross entropy loss, in listwise loss function, both of these are conducted over all items within the same list.\n",
    "- There're subsuquent works [[3]](https://dl.acm.org/doi/10.1145/3341981.3344221) that provides theoretically justifications for ListNet's softmax cross entropy loss. In particular they show that in a binary labeled setup, the loss bounds two popular learning to rank evaluation metrics: Mean Reciprocal Rank and Normalized Discounted Cumulative Gain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357d451-7b1b-4107-ab54-c6991ff576f3",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116b75d-c9c6-4f7b-b6fa-a90407970af1",
   "metadata": {},
   "source": [
    "We'll be using LETOR (Learning to Rank) 4.0 dataset [[6]](https://arxiv.org/abs/1306.2597) [[7]](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/letor-4-0/). There're also larger datasets such as, MSLR-WEB30k [[8]](https://www.microsoft.com/en-us/research/project/mslr/) or istella [[9]](http://blog.istella.it/istella-learning-to-rank-dataset/) which also comes in a similar raw format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46bd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://s3-us-west-2.amazonaws.com/xgboost-examples/MQ2008.rar\n",
    "#!unrar x MQ2008.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890fc0f1-9665-4873-a79c-b1a905225afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 qid:10002 1:0.007477 2:0.000000 3:1.000000 4:0.000000 5:0.007470 6:0.000000 7:0.000000 8:0.000000 9:0.000000 10:0.000000 11:0.471076 12:0.000000 13:1.000000 14:0.000000 15:0.477541 16:0.005120 17:0.000000 18:0.571429 19:0.000000 20:0.004806 21:0.768561 22:0.727734 23:0.716277 24:0.582061 25:0.000000 26:0.000000 27:0.000000 28:0.000000 29:0.780495 30:0.962382 31:0.999274 32:0.961524 33:0.000000 34:0.000000 35:0.000000 36:0.000000 37:0.797056 38:0.697327 39:0.721953 40:0.582568 41:0.000000 42:0.000000 43:0.000000 44:0.000000 45:0.000000 46:0.007042 #docid = GX008-86-4444840 inc = 1 prob = 0.086622\n",
      "\n",
      "0 qid:10002 1:0.603738 2:0.000000 3:1.000000 4:0.000000 5:0.603175 6:0.000000 7:0.000000 8:0.000000 9:0.000000 10:0.000000 11:0.000000 12:0.000000 13:0.122130 14:0.000000 15:0.000000 16:0.998377 17:0.375000 18:1.000000 19:0.000000 20:0.998128 21:0.000000 22:0.000000 23:0.154578 24:0.555676 25:0.000000 26:0.000000 27:0.000000 28:0.000000 29:0.071711 30:0.000000 31:0.000000 32:0.000000 33:0.000000 34:0.000000 35:0.000000 36:0.000000 37:0.000000 38:0.000000 39:0.117399 40:0.560607 41:0.000000 42:0.280000 43:0.000000 44:0.003708 45:0.333333 46:1.000000 #docid = GX037-06-11625428 inc = 0.0031586555555558 prob = 0.0897452\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show case some sample raw data\n",
    "input_path = 'MQ2008/Fold1/train.txt'\n",
    "\n",
    "with open(input_path) as f:\n",
    "    for _ in range(2):\n",
    "        line = f.readline()\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cacf40-f222-4606-917e-ff95be94bf2a",
   "metadata": {},
   "source": [
    "Each row represents a query-document pair in the dataset, with columns structured as follows:\n",
    "\n",
    "- First column contains the relevance label for this specific pair. A higher relevance label signifies a greater relevance between the query and the document\n",
    "- Second column contains the query ID.\n",
    "- Subsequent columns contain various features.\n",
    "- The row concludes with a comment about the pair, which includes the document's ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f78cd888-d56a-47f9-b3d9-4e880aa5e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_data(input_path):\n",
    "    labels = []\n",
    "    query_ids = []\n",
    "    features = []\n",
    "    with open(input_path) as f:\n",
    "        for line in f:\n",
    "            # filter out comment about the record\n",
    "            if \"#\" in line:\n",
    "                line = line[:line.index(\"#\")]\n",
    "\n",
    "            splitted_line = line.strip().split(\" \")\n",
    "            label = int(splitted_line[0])\n",
    "            labels.append(label)\n",
    "\n",
    "            query_id = splitted_line[1]\n",
    "            query_ids.append(query_id)\n",
    "\n",
    "            feature = [float(feature_str.split(':')[1]) for feature_str in splitted_line[2:]]\n",
    "            features.append(feature)\n",
    "\n",
    "    df = pd.DataFrame(features)\n",
    "    df[\"context\"] = query_ids\n",
    "    df[\"label\"] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8f0020-66f8-4943-8899-c71f0712abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45633, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582568</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>qid:10002</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560607</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>qid:10002</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021127</td>\n",
       "      <td>qid:10002</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qid:10002</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730347</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184564</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qid:10002</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3         4    5    6    7    8    9  ...        39   \n",
       "0  0.007477  0.0  1.0  0.0  0.007470  0.0  0.0  0.0  0.0  0.0  ...  0.582568  \\\n",
       "1  0.603738  0.0  1.0  0.0  0.603175  0.0  0.0  0.0  0.0  0.0  ...  0.560607   \n",
       "2  0.214953  0.0  0.0  0.0  0.213819  0.0  0.0  0.0  0.0  0.0  ...  1.000000   \n",
       "3  0.000000  0.0  1.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
       "4  1.000000  1.0  0.0  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  ...  0.730347   \n",
       "\n",
       "     40    41   42        43        44        45    context  label  split  \n",
       "0  0.00  0.00  0.0  0.000000  0.000000  0.007042  qid:10002      0  train  \n",
       "1  0.00  0.28  0.0  0.003708  0.333333  1.000000  qid:10002      0  train  \n",
       "2  0.00  0.00  0.0  1.000000  1.000000  0.021127  qid:10002      0  train  \n",
       "3  0.25  1.00  0.0  0.000000  0.000000  0.000000  qid:10002      0  train  \n",
       "4  1.00  0.84  0.0  0.184564  0.666667  0.000000  qid:10002      0  train  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate data under different cross validation folds together\n",
    "input_paths = [\n",
    "    'MQ2008/Fold1/train.txt',\n",
    "    'MQ2008/Fold2/train.txt',\n",
    "    'MQ2008/Fold3/train.txt',\n",
    "    'MQ2008/Fold4/train.txt',\n",
    "    'MQ2008/Fold5/train.txt'\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "for input_path in input_paths:\n",
    "    df = parse_raw_data(input_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_train = pd.concat(df_list, ignore_index=True)\n",
    "df_train[\"split\"] = \"train\"\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3e41a8-ac57-48a5-814b-daf8b07267d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15211, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711831</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197431</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>qid:15928</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313640</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212859</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>qid:15928</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760799</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309468</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>qid:15928</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178784</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>qid:15928</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784191</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>qid:15928</td>\n",
       "      <td>0</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3         4    5    6    7    8    9  ...        39   \n",
       "0  1.000000  0.0  0.0  0.0  1.000000  0.0  0.0  0.0  0.0  0.0  ...  0.711831  \\\n",
       "1  0.003315  0.0  1.0  0.0  0.005525  0.0  0.0  0.0  0.0  0.0  ...  0.313640   \n",
       "2  0.093923  0.0  0.0  0.0  0.093923  0.0  0.0  0.0  0.0  0.0  ...  0.760799   \n",
       "3  0.065193  0.0  0.0  0.0  0.065193  0.0  0.0  0.0  0.0  0.0  ...  1.000000   \n",
       "4  0.064088  0.0  0.0  0.0  0.064088  0.0  0.0  0.0  0.0  0.0  ...  0.784191   \n",
       "\n",
       "     40        41   42        43    44        45    context  label       split  \n",
       "0  0.50  0.290698  0.0  0.197431  0.50  0.000000  qid:15928      0  validation  \n",
       "1  0.50  0.255814  0.0  0.212859  0.25  0.214286  qid:15928      0  validation  \n",
       "2  0.25  0.127907  0.0  0.309468  1.00  0.357143  qid:15928      1  validation  \n",
       "3  0.25  0.069767  0.0  0.178784  0.50  0.428571  qid:15928      1  validation  \n",
       "4  0.50  0.255814  0.0  0.012703  0.25  0.214286  qid:15928      0  validation  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_paths = [\n",
    "    'MQ2008/Fold1/vali.txt',\n",
    "    'MQ2008/Fold2/vali.txt',\n",
    "    'MQ2008/Fold3/vali.txt',\n",
    "    'MQ2008/Fold4/vali.txt',\n",
    "    'MQ2008/Fold5/vali.txt'\n",
    "]\n",
    "\n",
    "df_list = []\n",
    "for input_path in input_paths:\n",
    "    df = parse_raw_data(input_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "df_validation = pd.concat(df_list, ignore_index=True)\n",
    "df_validation[\"split\"] = \"validation\"\n",
    "print(df_validation.shape)\n",
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58202ab7-9d2d-4bff-b8f0-13e056dec403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60844, 49)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    49116\n",
       "1     8004\n",
       "2     3724\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert context column to numerical indices, PyTorch doesn't take in string field\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df = pd.concat([df_train, df_validation], ignore_index=True)\n",
    "df[\"context\"] = label_encoder.fit_transform(df[\"context\"])\n",
    "\n",
    "# we can experiment with binary relevance label or the default graded relevance label\n",
    "# df.loc[df[\"label\"] == 2, \"label\"] = 1\n",
    "\n",
    "print(df.shape)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a9d409-983f-4717-b4a1-3c5c6172707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/table.py:761: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  return cls(pa.Table.from_pandas(*args, **kwargs))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', 'context', 'label'],\n",
       "    num_rows: 45633\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[df[\"split\"] == \"train\"].drop(columns=[\"split\"]).reset_index(drop=True)\n",
    "df_validation = df[df[\"split\"] == \"validation\"].drop(columns=[\"split\"]).reset_index(drop=True)\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_validation = Dataset.from_pandas(df_validation)\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80e51b-58c6-42ce-a59b-c3fec21a3d3e",
   "metadata": {},
   "source": [
    "These subsequent function/class for using deep learning on tabular data closely follows the ones introduced in Deep Learning for Tabular Data - PyTorch. [[nbviewer](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/deep_learning/tabular/deep_learning_tabular.ipynb)][[html](http://ethen8181.github.io/machine-learning/deep_learning/tabular/deep_learning_tabular.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7d2b47-c62e-4489-b537-d9e599d45360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example feature config\n",
    "# tabular_features_config = {\n",
    "#     \"0\": {\n",
    "#         \"dtype\": \"numerical\"\n",
    "#     }\n",
    "# }\n",
    "columns = [i for i in range(46)]\n",
    "tabular_features_config = {str(i): {\"dtype\": \"numerical\"} for i in columns}\n",
    "\n",
    "\n",
    "def tabular_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Use in conjunction with Dataloader's collate_fn for tabular data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    batch : dict\n",
    "        Dictionary with three keys: tabular_inputs, contexts, and labels. Tabular\n",
    "        inputs is a nested field, where each element is a feature_name -> float tensor\n",
    "        mapping. Contexts defines examples that share the same context/query. e.g.\n",
    "        {\n",
    "            'tabular_inputs': {'I1': tensor([0., 0.]), 'C1': tensor([ 888., 1313.])},\n",
    "            'labels': tensor([0, 0]),\n",
    "            'contexts': tensor([0, 0])\n",
    "        }\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    contexts = []\n",
    "    tabular_inputs = {}\n",
    "    for example in batch:\n",
    "        label = example[\"label\"]\n",
    "        labels.append(label)\n",
    "\n",
    "        context = example[\"context\"]\n",
    "        contexts.append(context)\n",
    "\n",
    "        for name in tabular_features_config:\n",
    "            feature = example[name]\n",
    "            if name not in tabular_inputs:\n",
    "                tabular_inputs[name] = [feature]\n",
    "            else:\n",
    "                tabular_inputs[name].append(feature)\n",
    "\n",
    "    for name in tabular_inputs:\n",
    "        tabular_inputs[name] = torch.FloatTensor(tabular_inputs[name])\n",
    "\n",
    "    batch = {\n",
    "        \"tabular_inputs\": tabular_inputs,\n",
    "        \"labels\": torch.LongTensor(labels),\n",
    "        \"contexts\": torch.LongTensor(contexts)\n",
    "    }\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35aa75eb-bb36-4ad4-8473-c71fedcff672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tabular_inputs': {'0': tensor([0.0075, 0.6037]),\n",
       "  '1': tensor([0., 0.]),\n",
       "  '2': tensor([1., 1.]),\n",
       "  '3': tensor([0., 0.]),\n",
       "  '4': tensor([0.0075, 0.6032]),\n",
       "  '5': tensor([0., 0.]),\n",
       "  '6': tensor([0., 0.]),\n",
       "  '7': tensor([0., 0.]),\n",
       "  '8': tensor([0., 0.]),\n",
       "  '9': tensor([0., 0.]),\n",
       "  '10': tensor([0.4711, 0.0000]),\n",
       "  '11': tensor([0., 0.]),\n",
       "  '12': tensor([1.0000, 0.1221]),\n",
       "  '13': tensor([0., 0.]),\n",
       "  '14': tensor([0.4775, 0.0000]),\n",
       "  '15': tensor([0.0051, 0.9984]),\n",
       "  '16': tensor([0.0000, 0.3750]),\n",
       "  '17': tensor([0.5714, 1.0000]),\n",
       "  '18': tensor([0., 0.]),\n",
       "  '19': tensor([0.0048, 0.9981]),\n",
       "  '20': tensor([0.7686, 0.0000]),\n",
       "  '21': tensor([0.7277, 0.0000]),\n",
       "  '22': tensor([0.7163, 0.1546]),\n",
       "  '23': tensor([0.5821, 0.5557]),\n",
       "  '24': tensor([0., 0.]),\n",
       "  '25': tensor([0., 0.]),\n",
       "  '26': tensor([0., 0.]),\n",
       "  '27': tensor([0., 0.]),\n",
       "  '28': tensor([0.7805, 0.0717]),\n",
       "  '29': tensor([0.9624, 0.0000]),\n",
       "  '30': tensor([0.9993, 0.0000]),\n",
       "  '31': tensor([0.9615, 0.0000]),\n",
       "  '32': tensor([0., 0.]),\n",
       "  '33': tensor([0., 0.]),\n",
       "  '34': tensor([0., 0.]),\n",
       "  '35': tensor([0., 0.]),\n",
       "  '36': tensor([0.7971, 0.0000]),\n",
       "  '37': tensor([0.6973, 0.0000]),\n",
       "  '38': tensor([0.7220, 0.1174]),\n",
       "  '39': tensor([0.5826, 0.5606]),\n",
       "  '40': tensor([0., 0.]),\n",
       "  '41': tensor([0.0000, 0.2800]),\n",
       "  '42': tensor([0., 0.]),\n",
       "  '43': tensor([0.0000, 0.0037]),\n",
       "  '44': tensor([0.0000, 0.3333]),\n",
       "  '45': tensor([0.0070, 1.0000])},\n",
       " 'labels': tensor([0, 0]),\n",
       " 'contexts': tensor([0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset_train, batch_size=2, collate_fn=tabular_collate_fn)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3fec5-64f9-4963-bc59-3b24c75abd6d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c09763d-0b9d-447e-b4bc-7a41718b8a47",
   "metadata": {},
   "source": [
    "Learning to rank based approaches regardless of whether it's pairwise or listwise requires data from the same context/group to be in the same mini-batch. Given our input data is in a pointwise format where each row represents a query-document pair, some additional transformations are necessary. We'll use some toy examples to illustrate these points before showing the full blown implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6dfe06-a80a-4518-a5cd-82a4dccdd197",
   "metadata": {},
   "source": [
    "In pairwise loss, the trick is to expand the original 1d tensor for computing a pairwise difference.\n",
    "\n",
    "- Context's pairwise difference signals which pairs belong to the same context. Pairs belonging to different context should be masked out during the loss calculation.\n",
    "- Label's pairwise difference is symmetric, and we only need to consider pairs where the difference is positive and convert it to a binary label.\n",
    "- Prediction score's pairwise difference will be input to our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7f59dc-73fa-43d5-b184-399b24adb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:\n",
      "  tensor([[ 0.,  1.,  1.,  1.,  0.],\n",
      "        [-1.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0., -1.],\n",
      "        [-1.,  0.,  0.,  0., -1.],\n",
      "        [ 0.,  1.,  1.,  1.,  0.]])\n",
      "context:\n",
      "  tensor([[ True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False],\n",
      "        [ True,  True,  True, False, False],\n",
      "        [False, False, False,  True,  True],\n",
      "        [False, False, False,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "pred_tensor = torch.FloatTensor([1, 2, 3, 1, 2])\n",
    "target_tensor = torch.Tensor([0, 1, 1, 1, 0])\n",
    "context_tensor = torch.Tensor([0, 0, 0, 1, 1])\n",
    "\n",
    "# 6 total positive pairs\n",
    "target_pairwise_diff = target_tensor.unsqueeze(0) - target_tensor.unsqueeze(1)\n",
    "print(\"label:\\n \", target_pairwise_diff)\n",
    "\n",
    "# context pairs, shows pairs from the first 3 examples belonging to the same context 0,\n",
    "# and pairs from example 4, 5 belongs to the same context 1\n",
    "context_pairwise_diff = context_tensor.unsqueeze(0) == context_tensor.unsqueeze(1)\n",
    "print(\"context:\\n \", context_pairwise_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e1826-20d5-4b56-befd-3b3d362619ea",
   "metadata": {},
   "source": [
    "In listwise loss, loss are calculated once for all data within the same context/group. Hence apart from the predicted scores and target/labels, we also need to know which examples belong to the same context/group. One common way to do this is to assume the examples are already sorted by context, and have a group length variable which stores each group's instance count.\n",
    "\n",
    "In the example below, we have 5 observations belonging to 2 contexts/groups. `[3, 2]` means the fist 3 items belongs to the first group, whereas the next 2 items belongs to the second group. `torch.split` then splits the original single tensor into grouped chunks, in a vanilla implementation, we can loop through each group and compute the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5d967a8-c26e-4999-bccf-407317dab9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8152, 1.3133])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tensor = torch.FloatTensor([1, 2, 3, 1, 2])\n",
    "target_tensor = torch.Tensor([0, 1, 1, 1, 0])\n",
    "group_length_tensor = torch.LongTensor([3, 2])\n",
    "\n",
    "losses = []\n",
    "for pred, target in zip(\n",
    "    torch.split(pred_tensor, group_length_tensor.tolist()),\n",
    "    torch.split(target_tensor, group_length_tensor.tolist())\n",
    "):\n",
    "    # equivalent to cross entropy\n",
    "    # loss = -torch.dot(target, F.log_softmax(pred, dim=0))\n",
    "    loss = F.cross_entropy(pred, target)\n",
    "    losses.append(loss)\n",
    "\n",
    "loop_listwise_loss = torch.stack(losses)\n",
    "loop_listwise_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b68d04-6a3e-4e9d-93c4-7054c9477119",
   "metadata": {},
   "source": [
    "A cleaner solution would be to pad these grouped chunks and perform the calculation in a batched manner. The padding values do matter, where we'll use an extremely small prediction score with 0 as its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29367c15-86fa-418d-8fcd-07329ebf4e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  2.0000e+00,  3.0000e+00],\n",
      "        [ 1.0000e+00,  2.0000e+00, -1.0000e+04]])\n",
      "tensor([[0., 1., 1.],\n",
      "        [1., 0., 0.]])\n",
      "tensor([1.8152, 1.3133])\n"
     ]
    }
   ],
   "source": [
    "pred_group = torch.split(pred_tensor, group_length_tensor.tolist())\n",
    "target_group = torch.split(target_tensor, group_length_tensor.tolist())\n",
    "pred_pad = pad_sequence(pred_group, batch_first=True, padding_value=-1e4)\n",
    "target_pad = pad_sequence(target_group, batch_first=True, padding_value=0.0)\n",
    "print(pred_pad)\n",
    "print(target_pad)\n",
    "\n",
    "loss_fct = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "batch_listwise_loss = loss_fct(pred_pad, target_pad)\n",
    "print(batch_listwise_loss)\n",
    "\n",
    "assert torch.equal(loop_listwise_loss, batch_listwise_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f52c59-a34a-4446-b072-135630adde8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_loss(logits, labels, contexts):    \n",
    "    logits_positive = logits[:, 0]\n",
    "    logits_positive_diff = logits_positive.unsqueeze(0) - logits_positive.unsqueeze(1)\n",
    "    \n",
    "    labels_pairwise_diff = labels.unsqueeze(0) - labels.unsqueeze(1)\n",
    "    labels_positive_mask = labels_pairwise_diff > 0\n",
    "    context_pairwise_diff = contexts.unsqueeze(0) == contexts.unsqueeze(1)\n",
    "    \n",
    "    loss_fct = nn.LogSigmoid()\n",
    "    logits_positive_masked = torch.masked_select(logits_positive_diff, labels_positive_mask * context_pairwise_diff)\n",
    "    if len(logits_positive_masked) == 0:\n",
    "        pairwise_loss = torch.tensor(0.0, requires_grad=True).to(logits.device)\n",
    "    else:\n",
    "        pairwise_loss = -loss_fct(logits_positive_masked).mean()\n",
    "\n",
    "    return pairwise_loss\n",
    "\n",
    "\n",
    "def compute_listwise_loss(logits, labels, contexts):\n",
    "    sorted_contexts, sorted_indices = torch.sort(contexts)\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "    logits_positive = logits[:, 0]\n",
    "    sorted_logits_positive = logits_positive[sorted_indices]\n",
    "\n",
    "    # contexts should already be sorted, using unique_consecutive as opposed to\n",
    "    # unique for avoiding additional sorting\n",
    "    unique_contexts, group_length = torch.unique_consecutive(contexts, return_counts=True)\n",
    "\n",
    "    logits_positive_group = torch.split(sorted_logits_positive, group_length.tolist())\n",
    "    labels_group = torch.split(sorted_labels, group_length.tolist())\n",
    "\n",
    "    # for logits, pad with an extremely small prediction score, this default value works even\n",
    "    # when using float16 mixed precision training\n",
    "    logits_pad = pad_sequence(logits_positive_group, batch_first=True, padding_value=-1e+4)\n",
    "    labels_pad = pad_sequence(labels_group, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    # we ensure there are more than 1 examples and at least 1 positive\n",
    "    # examples per group/context\n",
    "    group_mask = (group_length > 1) & (labels_pad.sum(dim=1) > 0)\n",
    "    logits_pad = logits_pad[group_mask]\n",
    "    labels_pad = labels_pad[group_mask]\n",
    "\n",
    "    if len(logits_pad) > 0:\n",
    "        loss_fct = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        listwise_loss = loss_fct(logits_pad, labels_pad.float())\n",
    "    else:\n",
    "        listwise_loss = torch.tensor(0.0, requires_grad=True).to(logits.device)            \n",
    "\n",
    "    return listwise_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e54393-7692-4bab-be1d-344e237bb49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_layers(input_dim: int, mlp_config):\n",
    "    \"\"\"\n",
    "    Construct MLP, a.k.a. Feed forward layers based on input config.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim : \n",
    "        Input dimension for the first layer.\n",
    "\n",
    "    mlp_config : list of dictionary with mlp spec.\n",
    "        An example is shown below, the only mandatory parameter is hidden size.\n",
    "        ```\n",
    "        [\n",
    "            {\n",
    "                \"hidden_size\": 1024,\n",
    "                \"dropout_p\": 0.1,\n",
    "                \"activation_function\": \"ReLU\",\n",
    "                \"activation_function_kwargs\": {},\n",
    "                \"normalization_function\": \"LayerNorm\"\n",
    "                \"normalization_function_kwargs\": {\"eps\": 1e-05}\n",
    "            }\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nn.Sequential :\n",
    "        Sequential layer converted from input mlp_config. If mlp_config\n",
    "        is None, then this returned value will also be None.\n",
    "\n",
    "    current_dim :\n",
    "        Dimension for the last layer.\n",
    "    \"\"\"\n",
    "    if mlp_config is None:\n",
    "        return None, input_dim\n",
    "\n",
    "    layers = []\n",
    "    current_dim = input_dim\n",
    "    for config in mlp_config:\n",
    "        hidden_size = config[\"hidden_size\"]\n",
    "        dropout_p = config.get(\"dropout_p\", 0.0)\n",
    "        activation_function = config.get(\"activation_function\")\n",
    "        activation_function_kwargs = config.get(\"activation_function_kwargs\", {})\n",
    "        normalization_function = config.get(\"normalization_function\")\n",
    "        normalization_function_kwargs = config.get(\"normalization_function_kwargs\", {})\n",
    "\n",
    "        linear = nn.Linear(current_dim, hidden_size)\n",
    "        layers.append(linear)\n",
    "\n",
    "        if normalization_function:\n",
    "            normalization = getattr(nn, normalization_function)(hidden_size, **normalization_function_kwargs)\n",
    "            layers.append(normalization)\n",
    "\n",
    "        if activation_function:\n",
    "            activation = getattr(nn, activation_function)(**activation_function_kwargs)\n",
    "            layers.append(activation)\n",
    "\n",
    "        dropout = nn.Dropout(p=dropout_p)\n",
    "        layers.append(dropout)\n",
    "        current_dim = hidden_size\n",
    "\n",
    "    return nn.Sequential(*layers), current_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e1c3a16-6edd-4227-a5fd-83905380569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModelConfig(PretrainedConfig):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tabular_features_config=None,\n",
    "        mlp_config=None,\n",
    "        num_labels=1,\n",
    "        loss_name=\"listwise\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tabular_features_config = tabular_features_config\n",
    "        self.mlp_config = mlp_config\n",
    "        self.num_labels = num_labels\n",
    "        self.loss_name = loss_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99aa42ef-f172-48b6-bd5d-bc392dc284d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(PreTrainedModel):\n",
    "\n",
    "    config_class = TabularModelConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings, output_dim = self.init_tabular_parameters(config.tabular_features_config)\n",
    "        self.mlp, output_dim = get_mlp_layers(output_dim, config.mlp_config)\n",
    "        self.head = nn.Linear(output_dim, config.num_labels)\n",
    "\n",
    "        if config.loss_name == \"pairwise\":\n",
    "            self.loss_function = compute_pairwise_loss\n",
    "        else:\n",
    "            self.loss_function = compute_listwise_loss\n",
    "\n",
    "    def forward(self, tabular_inputs, contexts, labels=None):\n",
    "        concatenated_inputs = self.concatenate_tabular_inputs(\n",
    "            tabular_inputs,\n",
    "            self.config.tabular_features_config\n",
    "        )\n",
    "        mlp_outputs = self.mlp(concatenated_inputs)\n",
    "        logits = self.head(mlp_outputs)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(logits, labels, contexts)\n",
    "\n",
    "        return loss, logits, contexts\n",
    "\n",
    "    def concatenate_tabular_inputs(self, inputs, tabular_features_config):\n",
    "        numerical_inputs = []\n",
    "        categorical_inputs = []\n",
    "        for name, config in tabular_features_config.items():\n",
    "            if config[\"dtype\"] == \"categorical\":\n",
    "                feature_name = f\"{name}_embedding\"\n",
    "                share_embedding = config.get(\"share_embedding\")\n",
    "                if share_embedding:\n",
    "                    feature_name = f\"{share_embedding}_embedding\"\n",
    "\n",
    "                embedding = self.embeddings[feature_name]\n",
    "                features = inputs[name].type(torch.long)\n",
    "                embed = embedding(features)\n",
    "                categorical_inputs.append(embed)\n",
    "            elif config[\"dtype\"] == \"numerical\":\n",
    "                features = inputs[name].type(torch.float32)\n",
    "                if len(features.shape) == 1:\n",
    "                    features = features.unsqueeze(dim=1)\n",
    "\n",
    "                numerical_inputs.append(features)\n",
    "\n",
    "        if len(numerical_inputs) > 0:\n",
    "            numerical_inputs = torch.cat(numerical_inputs, dim=-1)\n",
    "\n",
    "        categorical_inputs.append(numerical_inputs)\n",
    "        concatenated_inputs = torch.cat(categorical_inputs, dim=-1)\n",
    "        return concatenated_inputs\n",
    "\n",
    "    def init_tabular_parameters(self, tabular_features_config):\n",
    "        embeddings = {}\n",
    "        output_dim = 0\n",
    "        for name, config in tabular_features_config.items():\n",
    "            if config[\"dtype\"] == \"categorical\":\n",
    "                feature_name = f\"{name}_embedding\"\n",
    "                # create new embedding layer for categorical features if share_embedding is None\n",
    "                share_embedding = config.get(\"share_embedding\")\n",
    "                if share_embedding:\n",
    "                    share_embedding_config = model.pairwise_features_info[share_embedding]\n",
    "                    embedding_size = share_embedding_config[\"embedding_size\"]\n",
    "                else:\n",
    "                    embedding_size = config[\"embedding_size\"]\n",
    "                    embedding = nn.Embedding(config[\"vocab_size\"], embedding_size)\n",
    "                    embeddings[feature_name] = embedding\n",
    "\n",
    "                output_dim += embedding_size\n",
    "            elif config[\"dtype\"] == \"numerical\":\n",
    "                output_dim += 1\n",
    "\n",
    "        return nn.ModuleDict(embeddings), output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38d32ab-2afe-450a-a13c-eec10aafb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters:  708097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeddings): ModuleDict()\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=46, out_features=1024, bias=True)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (head): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_config = [\n",
    "    {\n",
    "        \"hidden_size\": 1024,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    },\n",
    "    {\n",
    "        \"hidden_size\": 512,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    },\n",
    "    {\n",
    "        \"hidden_size\": 256,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    }\n",
    "]\n",
    "config = TabularModelConfig(tabular_features_config, mlp_config, loss_name=\"listwise\")\n",
    "model = TabularModel(config).to(device)\n",
    "print(\"# of parameters: \", model.num_parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "117d41a4-cac1-48f6-bb50-7d3a124143ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds, round_digits: int = 3):\n",
    "    \"\"\"Reports NDCG metrics\"\"\"\n",
    "    (y_pred, context), y_true = eval_preds\n",
    "\n",
    "    y_score = y_pred[:, 0]\n",
    "\n",
    "    ndcg_metrics = torchmetrics.retrieval.RetrievalNormalizedDCG(top_k=5)\n",
    "    ndcg = ndcg_metrics(torch.FloatTensor(y_score), torch.FloatTensor(y_true), indexes=torch.LongTensor(context))\n",
    "    return {\n",
    "        'ndcg': ndcg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755e6617-93b5-4021-9207-9e88fe1adb23",
   "metadata": {},
   "source": [
    "When training a learning to rank model, an important detail is to prevent data shuffling in our data loader so data from the same context can be grouped together in a mini-batch. At the time of writing this, huggingface transformer's Trainer will by default enable shuffling on our train dataset. We quickly override that behaviour by using `get_test_dataloader` even for our train dataloader. This addresses the issue with the least amount of code with the quirk being now `per_device_eval_batch_size` will also be used for `per_device_train_batch_size`, which can be a bit confusing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f93b9483-08f1-4a41-bc0f-486474cecaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularRankingTrainer(Trainer):\n",
    "\n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        We should confirm context from this data loader isn't shuffled.\n",
    "\n",
    "        ```\n",
    "        dl = trainer.get_train_dataloader()\n",
    "        next(iter(dl))[\"contexts\"]\n",
    "        ```\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "\n",
    "        return super().get_test_dataloader(self.train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c08f1bf-6419-46c8-8ef0-86bae08d1c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8900' max='8900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8900/8900 08:24, Epoch 49/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>21.815300</td>\n",
       "      <td>20.822407</td>\n",
       "      <td>0.489811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>21.282800</td>\n",
       "      <td>20.460518</td>\n",
       "      <td>0.510252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>20.930400</td>\n",
       "      <td>20.099937</td>\n",
       "      <td>0.522047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>20.950900</td>\n",
       "      <td>19.581291</td>\n",
       "      <td>0.556249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>20.370300</td>\n",
       "      <td>19.352951</td>\n",
       "      <td>0.573809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>20.088400</td>\n",
       "      <td>18.906128</td>\n",
       "      <td>0.593706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>19.419700</td>\n",
       "      <td>18.469860</td>\n",
       "      <td>0.610612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>19.186300</td>\n",
       "      <td>18.217682</td>\n",
       "      <td>0.618409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>19.342700</td>\n",
       "      <td>17.893827</td>\n",
       "      <td>0.647029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>18.695400</td>\n",
       "      <td>17.563608</td>\n",
       "      <td>0.658074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>18.484600</td>\n",
       "      <td>17.467468</td>\n",
       "      <td>0.663601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>17.947200</td>\n",
       "      <td>17.103064</td>\n",
       "      <td>0.675647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>17.924100</td>\n",
       "      <td>16.729994</td>\n",
       "      <td>0.684831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>17.969500</td>\n",
       "      <td>16.560793</td>\n",
       "      <td>0.689212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>17.559800</td>\n",
       "      <td>16.929613</td>\n",
       "      <td>0.694637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>17.424100</td>\n",
       "      <td>16.342243</td>\n",
       "      <td>0.697590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>17.035300</td>\n",
       "      <td>16.118475</td>\n",
       "      <td>0.698370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"tabular\",\n",
    "    num_train_epochs=50,\n",
    "    learning_rate=0.001,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    do_train=True,\n",
    "    # we are collecting all tabular features into a single entry\n",
    "    # tabular_inputs during collate function, this is to prevent\n",
    "    # huggingface trainer from removing these features while processing\n",
    "    # our dataset\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = TabularRankingTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    data_collator=tabular_collate_fn,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_validation,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# on this multi-level graded validation dataset, pairwise/listwise\n",
    "# loss gives a 0.69 - 0.70 NDCG@5\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503763cc-45e7-4972-9d65-a7bc7763a274",
   "metadata": {},
   "source": [
    "In computational advertising, particularly its click through rate application, pointwise loss function still remains to be the dominating approach due to:\n",
    "\n",
    "- Calibrated Score. For ad auction to properly take place, a model's prediction score needs to be treated as a click probability instead of a score that only denotes ordering or perference.\n",
    "- Data Sparsity. Pairwise/listwise approach relies on events that have positive outcomes. These approaches compare records with positive events to those without for building their loss functions. However, in practice, these positive events can be sparse, meaning there are far fewer instances of user engagement (clicks) than non-engagement. This sparsity implies that using pairwise or listwise methods would result in a significant loss of available data and might hinder downstream performance. Pointwise approach doesn't have this limitation and can make better use of available data.\n",
    "\n",
    "To preserve the benefits from both pointwise and pairwise/listwise approaches, an intuitive way is to calculate weighted average of the two\n",
    "loss functions to take advantage from both sides [[4]](https://dl.acm.org/doi/10.1145/2783258.2788582) [[5]](https://arxiv.org/abs/2208.06164). Given the sparsity of pairwise data, it can be beneficial to create pseudo pairs to prevent the model to be biased towards classification loss. e.g. we can form more pairs artificially by grouping impressions from different request but under the same session and user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95501d1d-4539-4e87-9ecf-ffa77a18a240",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ac750-e4b9-456e-9db8-3a1d4ccaa5be",
   "metadata": {},
   "source": [
    "- [[1]](https://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf) Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, Greg Hullender - Learning to Rank using Gradient Descent - 2005\n",
    "- [[2]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2007-40.pdf) Zhe Cao, Tao Qin, Ming-Feng Tsai, et al. - Learning to Rank: From Pairwise Approach to Listwise Approach - 2007\n",
    "- [[3]](https://dl.acm.org/doi/10.1145/3341981.3344221) Sebastian Bruch, Xuanhui Wang, Michael Bendersky, Marc Najork - An Analysis of the Softmax Cross Entropy Loss for Learning-to-Rank with Binary Relevance - 2019\n",
    "- [[4]](https://dl.acm.org/doi/10.1145/2783258.2788582) Cheng Li, Yue Lu, Qiaozhu Mei, Dong Wang, Sandeep Pandey - Click-through Prediction for Advertising in Twitter Timeline - 2015\n",
    "- [[5]](https://arxiv.org/abs/2208.06164) Shuguang Han et al. - Joint Optimization of Ranking and Calibration with Contextualized Hybrid Model - 2022\n",
    "- [[6]](https://arxiv.org/abs/1306.2597) Tao Qin, Tie-Yan Liu - Introducing LETOR 4.0 Datasets - 2013\n",
    "- [[7]](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/letor-4-0/) LETOR: Learning to Rank for Information Retrieval - LETOR 4.0\n",
    "- [[8]](https://www.microsoft.com/en-us/research/project/mslr/) Microsoft Learning to Rank Datasets\n",
    "- [[9]](http://blog.istella.it/istella-learning-to-rank-dataset/) Blog: Istella Learning to Rank dataset\n",
    "- [[10]](https://embracingtherandom.com/machine-learning/tensorflow/ranking/deep-learning/learning-to-rank-part-2/) Blog: Learning to rank is good for your ML career - Part 2: let’s implement ListNet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
