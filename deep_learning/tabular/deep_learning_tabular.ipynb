{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fb9033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    html {\n",
       "        font-size: 18px !important;\n",
       "    }\n",
       "\n",
       "    body {\n",
       "        background-color: #FFF !important;\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    body .notebook-app {\n",
       "        background-color: #FFF !important;\n",
       "    }\n",
       "\n",
       "    #header {\n",
       "        box-shadow: none !important;\n",
       "    }\n",
       "\n",
       "    #notebook {\n",
       "        padding-top: 0px;\n",
       "    }\n",
       "\n",
       "    #notebook-container {\n",
       "        box-shadow: none;\n",
       "        -webkit-box-shadow: none;\n",
       "        padding: 10px;\n",
       "    }\n",
       "\n",
       "    div.cell {\n",
       "        width: 1000px;\n",
       "        margin-left: 0% !important;\n",
       "        margin-right: auto;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border: 1px dashed #CCCCCC;\n",
       "    }\n",
       "\n",
       "    .edit_mode div.cell.selected {\n",
       "        border: 1px dashed #828282;\n",
       "    }\n",
       "\n",
       "    div.output_wrapper {\n",
       "        margin-top: 8px;\n",
       "    }\n",
       "\n",
       "    a {\n",
       "        color: #383838;\n",
       "    }\n",
       "\n",
       "    code,\n",
       "    kbd,\n",
       "    pre,\n",
       "    samp {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem !important;\n",
       "    }\n",
       "\n",
       "    h1 {\n",
       "        font-size: 2rem !important;\n",
       "        font-weight: 500 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: uppercase !important;\n",
       "    }\n",
       "\n",
       "    h2 {\n",
       "        font-size: 1.8rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        letter-spacing: 3px !important;\n",
       "        text-transform: none !important;\n",
       "    }\n",
       "\n",
       "    h3 {\n",
       "        font-size: 1.5rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        font-style: italic !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    h4,\n",
       "    h5,\n",
       "    h6 {\n",
       "        font-size: 1rem !important;\n",
       "        font-weight: 400 !important;\n",
       "        display: block !important;\n",
       "    }\n",
       "\n",
       "    .prompt {\n",
       "        font-family: 'Menlo', monospace !important;\n",
       "        font-size: 0.75rem;\n",
       "        text-align: right;\n",
       "        line-height: 1.21429rem;\n",
       "    }\n",
       "\n",
       "    /* INTRO PAGE */\n",
       "\n",
       "    .toolbar_info,\n",
       "    .list-container {\n",
       "        ;\n",
       "    }\n",
       "    /* NOTEBOOK */\n",
       "\n",
       "    div#header-container {\n",
       "        display: none !important;\n",
       "    }\n",
       "\n",
       "    div#notebook {\n",
       "        border-top: none;\n",
       "        font-size: 1rem;\n",
       "    }\n",
       "\n",
       "    div.input_prompt {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .code_cell div.input_prompt:after,\n",
       "    div.output_prompt:after {\n",
       "        content: '\\25b6';\n",
       "    }\n",
       "\n",
       "    div.output_prompt {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    div.input_area {\n",
       "        border-radius: 0px;\n",
       "        border: 1px solid #d8d8d8;\n",
       "    }\n",
       "\n",
       "    div.output_area pre {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    div.output_subarea {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .rendered_html pre,\n",
       "    .rendered_html table,\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        border: 1px #828282 solid;\n",
       "        font-size: 0.75rem;\n",
       "        font-family: 'Menlo', monospace;\n",
       "    }\n",
       "\n",
       "    .rendered_html th,\n",
       "    .rendered_html tr,\n",
       "    .rendered_html td {\n",
       "        padding: 5px 10px;\n",
       "    }\n",
       "\n",
       "    .rendered_html th {\n",
       "        font-weight: normal;\n",
       "        background: #f8f8f8;\n",
       "    }\n",
       "\n",
       "    a:link{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:visited{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:hover{\n",
       "       font-weight: bold;\n",
       "       color: #1d3b84;\n",
       "    }\n",
       "    a:focus{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    a:active{\n",
       "       font-weight: bold;\n",
       "       color:#447adb;\n",
       "    }\n",
       "    .rendered_html :link {\n",
       "       text-decoration: underline; \n",
       "    }\n",
       "\n",
       "    div.output_html {\n",
       "        font-weight: 1rem;\n",
       "        font-family: 'Source Sans Pro', \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    }\n",
       "\n",
       "    table.dataframe tr {\n",
       "        border: 1px #CCCCCC;\n",
       "    }\n",
       "\n",
       "    div.cell.selected {\n",
       "        border-radius: 0px;\n",
       "    }\n",
       "\n",
       "    div.cell.edit_mode {\n",
       "        border-radius: 0px;\n",
       "        border: thin solid #CF5804;\n",
       "    }\n",
       "\n",
       "    span.ansiblue {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    span.ansigray {\n",
       "        color: #d8d8d8;\n",
       "    }\n",
       "\n",
       "    span.ansigreen {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    span.ansipurple {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    span.ansired {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    span.ansiyellow {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    div.output_stderr {\n",
       "        background-color: #D43132;\n",
       "    }\n",
       "\n",
       "    div.output_stderr pre {\n",
       "        color: #e8e8e8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython.CodeMirror {\n",
       "        background: #F8F8F8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython div.CodeMirror-selected {\n",
       "        background: #e8e8e8 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-gutters {\n",
       "        background: #F8F8F8;\n",
       "        border-right: 0px;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-linenumber {\n",
       "        color: #b8b8b8;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-cursor {\n",
       "        border-left: 1px solid #585858 !important;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-atom {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-number {\n",
       "        color: #C74483;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-property,\n",
       "    .cm-s-ipython span.cm-attribute {\n",
       "        color: #688A0A;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-keyword {\n",
       "        font-weight: normal;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-string {\n",
       "        color: #D9AA00;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-operator {\n",
       "        font-weight: normal;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-builtin {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-variable-2 {\n",
       "        color: #2B88D9;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-def {\n",
       "        color: #00A397;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-error {\n",
       "        background: #FFBDBD;\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-tag {\n",
       "        color: #D43132;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython span.cm-link {\n",
       "        color: #975DDE;\n",
       "    }\n",
       "\n",
       "    .cm-s-ipython .CodeMirror-matchingbracket {\n",
       "        text-decoration: underline;\n",
       "         !important;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    scale:100,\n",
       "                        availableFonts: [],\n",
       "                        preferredFont:null,\n",
       "                        webFont: \"TeX\",\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for loading notebook's format\n",
    "import os\n",
    "\n",
    "# path : store the current path to convert back to it later\n",
    "path = os.getcwd()\n",
    "os.chdir(os.path.join('..', '..', 'notebook_format'))\n",
    "\n",
    "from formats import load_style\n",
    "load_style(css_style='custom2.css', plot_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90f79036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Ethen\n",
      "\n",
      "Last updated: 2023-08-23 21:35:27\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.6\n",
      "IPython version      : 8.13.2\n",
      "\n",
      "transformers: 4.31.0\n",
      "datasets    : 2.14.4\n",
      "torch       : 2.0.1\n",
      "numpy       : 1.23.2\n",
      "pandas      : 2.0.1\n",
      "sklearn     : 1.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "\n",
    "%load_ext watermark\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_dataset,\n",
    "    disable_progress_bar\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from transformers import (\n",
    "    PretrainedConfig,\n",
    "    PreTrainedModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%watermark -a 'Ethen' -d -t -v -u -p transformers,datasets,torch,numpy,pandas,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091319c4",
   "metadata": {},
   "source": [
    "# Deep Learning for Tabular Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf2508",
   "metadata": {},
   "source": [
    "While deep learning's achievements are often highlighted in areas like computer vision and natural language processing, a lesser-discussed yet potent application involves applying deep learning to tabular data.\n",
    "\n",
    "A key technique to maximize deep learning's potential with tabular data involves using embeddings for categorical variables [[4]](https://www.fast.ai/posts/2018-04-29-categorical-embeddings.html). This means representing categories in a lower-dimensional numeric space, capturing intricate relationships between them. For instance, this could reveal geographic connections between high-cardinality categorical features like zip codes, without explicit guidance. Even for continuous features such as days of the week, it's still worth exploring the potential advantages of treating them as categorical features and utilizing embeddings.\n",
    "\n",
    "Furthermore, embeddings offer benefits beyond their initial use. Once trained, these embeddings can be employed in other contexts. For example, they can serve as features for tree-based models, granting them the enriched knowledge gleaned from deep learning. This cross-application of embeddings underscores their versatility and their ability to enhance various modeling techniques.\n",
    "\n",
    "In this article, we'll be looking at some bare minimum steps for training a self-defined deep learning model and training it using huggingface Trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41014b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28125de",
   "metadata": {},
   "source": [
    "We'll be using a downsampled criteo dataset, which originated from a Kaggle competition [[2]](https://www.kaggle.com/competitions/criteo-display-ad-challenge/data). Though after the competition ended, those original data files became unavailable on the platform. We turned to an alternative source for downloading a similar dataset [[1]](https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/). Each row corresponds to a display ad served by Criteo. Positive (clicked) and negatives (non-clicked) examples have both been subsampled at different rates in order to reduce the dataset size. Fields in this dataset includes:\n",
    "\n",
    "- Label: Target variable that indicates if an ad was clicked (1) or not (0).\n",
    "- I1-I13: A total of 13 columns of integer features (mostly count features).\n",
    "- C1-C26: A total of 26 columns of categorical features. The values of these features have been hashed onto 32 bits for anonymization purposes. \n",
    "\n",
    "Unfortunately, the meanings of these features aren't disclosed.\n",
    "\n",
    "Note, there are many ways to implement a data preprocessing step, the baseline approach we'll be performing here is to:\n",
    "\n",
    "- Encode categorical columns as distinct numerical ids.\n",
    "- Standardize/Scale numerical columns.\n",
    "- Given the un-balanced dataset, we perform random downsampling on the negative class for our training set, while keeping the test set unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d6cfa-88de-4a89-92d6-cca93888da5b",
   "metadata": {},
   "source": [
    "```python\n",
    "# one time code for creating a sampled criteo dataset\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_criteo_data(gzip_file: str, num_records: int, output_path: str):\n",
    "    \"\"\"\n",
    "    Parse gzipped criteo dataset and save it into a tabular parquet format.\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10',\n",
    "        'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n",
    "        'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18',\n",
    "        'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'\n",
    "    ]\n",
    "\n",
    "    dtype = {}\n",
    "    for col in columns:\n",
    "        if \"C\" in col:\n",
    "            dtype[col] = \"string\"\n",
    "        elif col == \"label\":\n",
    "            dtype[col] = \"int\"\n",
    "        else:\n",
    "            dtype[col] = \"float\"\n",
    "            \n",
    "    lines = []\n",
    "    with gzip.open(gzip_file, 'r') as f_in:\n",
    "        for i in range(num_records):\n",
    "            line = f_in.readline()\n",
    "            line = str(line, encoding=\"utf-8\")\n",
    "            line = line.strip().split(\"\\t\")\n",
    "            lines.append(line)\n",
    "\n",
    "    df = pd.DataFrame(lines, columns=columns)\n",
    "    df = df.replace(\"\", None)\n",
    "    df = df.astype(dtype)\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    \n",
    "\n",
    "gzip_file = \"day_0.gz\"\n",
    "num_records = 1000000\n",
    "output_path = \"criteo_sampled.parquet\"\n",
    "parse_criteo_data(gzip_file, num_records, output_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6853b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d20856aa</td>\n",
       "      <td>b8170bba</td>\n",
       "      <td>9512c20b</td>\n",
       "      <td>c38e2f28</td>\n",
       "      <td>14f65a5d</td>\n",
       "      <td>25b1b089</td>\n",
       "      <td>d7c1fc0b</td>\n",
       "      <td>7caf609c</td>\n",
       "      <td>30436bfc</td>\n",
       "      <td>ed10571d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d20856aa</td>\n",
       "      <td>a1eb1511</td>\n",
       "      <td>9512c20b</td>\n",
       "      <td>febfd863</td>\n",
       "      <td>a3323ca1</td>\n",
       "      <td>c8e1ee56</td>\n",
       "      <td>1752e9e8</td>\n",
       "      <td>75350c8a</td>\n",
       "      <td>991321ea</td>\n",
       "      <td>b757e957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d20856aa</td>\n",
       "      <td>628f1b8d</td>\n",
       "      <td>9512c20b</td>\n",
       "      <td>c38e2f28</td>\n",
       "      <td>14f65a5d</td>\n",
       "      <td>25b1b089</td>\n",
       "      <td>d7c1fc0b</td>\n",
       "      <td>34a9b905</td>\n",
       "      <td>ff654802</td>\n",
       "      <td>ed10571d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1f7fc70b</td>\n",
       "      <td>a1eb1511</td>\n",
       "      <td>9512c20b</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>dc209cd3</td>\n",
       "      <td>b8a81fb0</td>\n",
       "      <td>30436bfc</td>\n",
       "      <td>b757e957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d20856aa</td>\n",
       "      <td>d9f758ff</td>\n",
       "      <td>9512c20b</td>\n",
       "      <td>c709ec07</td>\n",
       "      <td>2b07677e</td>\n",
       "      <td>a89a92a5</td>\n",
       "      <td>aa137169</td>\n",
       "      <td>e619743b</td>\n",
       "      <td>cdc3217e</td>\n",
       "      <td>ed10571d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    I1     I2   I3     I4    I5   I6   I7    I8   I9  ...       C17   \n",
       "0      1   5.0  110.0  NaN   16.0   NaN  1.0  0.0  14.0  7.0  ...  d20856aa  \\\n",
       "1      0  32.0    3.0  5.0    NaN   1.0  0.0  0.0  61.0  5.0  ...  d20856aa   \n",
       "2      0   NaN  233.0  1.0  146.0   1.0  0.0  0.0  99.0  7.0  ...  d20856aa   \n",
       "3      0   NaN   24.0  NaN   11.0  24.0  NaN  0.0  56.0  3.0  ...  1f7fc70b   \n",
       "4      0  60.0  223.0  6.0   15.0   5.0  0.0  0.0   1.0  8.0  ...  d20856aa   \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24   \n",
       "0  b8170bba  9512c20b  c38e2f28  14f65a5d  25b1b089  d7c1fc0b  7caf609c  \\\n",
       "1  a1eb1511  9512c20b  febfd863  a3323ca1  c8e1ee56  1752e9e8  75350c8a   \n",
       "2  628f1b8d  9512c20b  c38e2f28  14f65a5d  25b1b089  d7c1fc0b  34a9b905   \n",
       "3  a1eb1511  9512c20b      <NA>      <NA>      <NA>  dc209cd3  b8a81fb0   \n",
       "4  d9f758ff  9512c20b  c709ec07  2b07677e  a89a92a5  aa137169  e619743b   \n",
       "\n",
       "        C25       C26  \n",
       "0  30436bfc  ed10571d  \n",
       "1  991321ea  b757e957  \n",
       "2  ff654802  ed10571d  \n",
       "3  30436bfc  b757e957  \n",
       "4  cdc3217e  ed10571d  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path = \"criteo_data/criteo_sampled.parquet\"\n",
    "df = pd.read_parquet(input_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de7066ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "feature_names = dense_features + sparse_features\n",
    "\n",
    "df[sparse_features] = df[sparse_features].fillna('-1')\n",
    "df[dense_features] = df[dense_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab18e90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1229.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.027875</td>\n",
       "      <td>0.019355</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1255.0</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2566.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        I1        I2        I3        I4        I5        I6   I7   \n",
       "0      1  0.000076  0.013750  0.000000  0.000039  0.000000  0.001033  0.0  \\\n",
       "1      0  0.000488  0.000375  0.016129  0.000000  0.000185  0.000000  0.0   \n",
       "2      0  0.000000  0.029125  0.003226  0.000353  0.000185  0.000000  0.0   \n",
       "3      0  0.000000  0.003000  0.000000  0.000027  0.004431  0.000000  0.0   \n",
       "4      0  0.000916  0.027875  0.019355  0.000036  0.000923  0.000000  0.0   \n",
       "\n",
       "         I8        I9  ...  C17    C18  C19     C20     C21     C22     C23   \n",
       "0  0.000771  0.001964  ...  3.0  138.0  9.0   970.0   161.0   221.0  1229.0  \\\n",
       "1  0.003186  0.001403  ...  3.0  117.0  9.0  1251.0  1114.0  1073.0   126.0   \n",
       "2  0.005139  0.001964  ...  3.0   75.0  9.0   970.0   161.0   221.0  1229.0   \n",
       "3  0.002929  0.000842  ...  1.0  117.0  9.0     0.0     0.0     0.0  1255.0   \n",
       "4  0.000103  0.002245  ...  3.0  160.0  9.0  1255.0  1711.0  1374.0   948.0   \n",
       "\n",
       "      C24   C25   C26  \n",
       "0  1401.0   2.0  20.0  \n",
       "1  1317.0  15.0  15.0  \n",
       "2   610.0  32.0  20.0  \n",
       "3  2059.0   2.0  15.0  \n",
       "4  2566.0  19.0  20.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encoding for categorical/sparse features\n",
    "# and scaling for numerical/dense features\n",
    "ordinal_encoder = OrdinalEncoder(min_frequency=30)\n",
    "df[sparse_features] = ordinal_encoder.fit_transform(df[sparse_features])\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df[dense_features] = min_max_scaler.fit_transform(df[dense_features])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e9ac9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    970960\n",
       "1     29040\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8799e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_negative(df: pd.DataFrame, frac: float = 0.5, random_state: int = 1234):\n",
    "    \"\"\"Given a binary classification task with 0/1 labels, downsample negative class (class 0) with the\n",
    "    specified fraction parameter.\n",
    "    \"\"\"\n",
    "    df_majority = df[df[\"label\"] == 0]\n",
    "    df_minority = df[df[\"label\"] == 1]\n",
    "    df_downsampled_majority = df_majority.sample(frac=frac, random_state=random_state)\n",
    "    df_downsampled = pd.concat([df_downsampled_majority, df_minority])\n",
    "    # shuffle the combined data frame\n",
    "    df_downsampled = df_downsampled.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdda3fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26'],\n",
      "    num_rows: 463068\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'I1': 0.0,\n",
       " 'I2': 0.005625,\n",
       " 'I3': 0.0,\n",
       " 'I4': 0.0,\n",
       " 'I5': 0.0007385524372230429,\n",
       " 'I6': 0.0,\n",
       " 'I7': 0.0,\n",
       " 'I8': 0.0,\n",
       " 'I9': 0.0005611672278338945,\n",
       " 'I10': 0.0,\n",
       " 'I11': 0.013513513513513514,\n",
       " 'I12': 0.000576345639540026,\n",
       " 'I13': 0.0,\n",
       " 'C1': 888.0,\n",
       " 'C2': 866.0,\n",
       " 'C3': 1134.0,\n",
       " 'C4': 292.0,\n",
       " 'C5': 379.0,\n",
       " 'C6': 0.0,\n",
       " 'C7': 1490.0,\n",
       " 'C8': 141.0,\n",
       " 'C9': 2.0,\n",
       " 'C10': 631.0,\n",
       " 'C11': 113.0,\n",
       " 'C12': 1406.0,\n",
       " 'C13': 4.0,\n",
       " 'C14': 400.0,\n",
       " 'C15': 882.0,\n",
       " 'C16': 11.0,\n",
       " 'C17': 3.0,\n",
       " 'C18': 138.0,\n",
       " 'C19': 11.0,\n",
       " 'C20': 114.0,\n",
       " 'C21': 1011.0,\n",
       " 'C22': 113.0,\n",
       " 'C23': 1209.0,\n",
       " 'C24': 835.0,\n",
       " 'C25': 2.0,\n",
       " 'C26': 23.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=1234, stratify=df[\"label\"])\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train_downsampled = downsample_negative(df_train)\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train_downsampled)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "print(dataset_train)\n",
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b6e7c-1cf5-46e1-9935-f9615ffedf1e",
   "metadata": {},
   "source": [
    "We'll specify a config mapping for tabular features that we'll be using across our batch collate function as well as model. This config mapping have features we wish to leverage as keys, and different value/enum specifying whether the field is numerical or categorical type. This will be beneficial to inform our model about the embedding size required for a categorical type as well as how many numerical fields are there to initiate the dense/feed forward layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131e3289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrating the functionality with 1 numerical and 1 categorical feature\n",
    "tabular_features_config = {\n",
    "    \"I1\": {\n",
    "        \"dtype\": \"numerical\",\n",
    "    },\n",
    "    \"C1\": {\n",
    "        \"dtype\": \"categorical\",\n",
    "        \"vocab_size\": len(ordinal_encoder.categories_[0]),\n",
    "        \"embedding_size\": 32\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def tabular_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Use in conjunction with Dataloader's collate_fn for tabular data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    batch : dict\n",
    "        Dictionary with two primary keys: tabular_inputs, and labels. Tabular\n",
    "        inputs is a nested field, where each element is a feature_name -> float tensor\n",
    "        mapping. e.g.\n",
    "        {\n",
    "            'tabular_inputs': {'I1': tensor([0., 0.]), 'C1': tensor([ 888., 1313.])},\n",
    "             'labels': tensor([0, 0])\n",
    "        }\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    tabular_inputs = {}\n",
    "    for example in batch:\n",
    "        label = example[\"label\"]\n",
    "        labels.append(label)\n",
    "\n",
    "        for name in tabular_features_config:\n",
    "            feature = example[name]\n",
    "            if name not in tabular_inputs:\n",
    "                tabular_inputs[name] = [feature]\n",
    "            else:\n",
    "                tabular_inputs[name].append(feature)\n",
    "\n",
    "    for name in tabular_inputs:\n",
    "        tabular_inputs[name] = torch.FloatTensor(tabular_inputs[name])\n",
    "\n",
    "    batch = {\n",
    "        \"tabular_inputs\": tabular_inputs,\n",
    "        \"labels\": torch.LongTensor(labels)\n",
    "    }\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a3f1aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tabular_inputs': {'I1': tensor([0., 0.]), 'C1': tensor([ 888., 1313.])},\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader(dataset_train, batch_size=2, collate_fn=tabular_collate_fn)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6417d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tabular_inputs': {'I1': tensor([0., 0.]),\n",
       "  'I2': tensor([0.0056, 0.0180]),\n",
       "  'I3': tensor([0., 0.]),\n",
       "  'I4': tensor([0.0000, 0.0012]),\n",
       "  'I5': tensor([0.0007, 0.0002]),\n",
       "  'I6': tensor([0., 0.]),\n",
       "  'I7': tensor([0., 0.]),\n",
       "  'I8': tensor([0.0000, 0.0217]),\n",
       "  'I9': tensor([0.0006, 0.0017]),\n",
       "  'I10': tensor([0., 0.]),\n",
       "  'I11': tensor([0.0135, 0.0045]),\n",
       "  'I12': tensor([0.0006, 0.0168]),\n",
       "  'I13': tensor([0., 0.]),\n",
       "  'C1': tensor([ 888., 1313.]),\n",
       "  'C2': tensor([866., 276.]),\n",
       "  'C3': tensor([1134., 3660.]),\n",
       "  'C4': tensor([292., 213.]),\n",
       "  'C5': tensor([379., 963.]),\n",
       "  'C6': tensor([0., 2.]),\n",
       "  'C7': tensor([1490., 2072.]),\n",
       "  'C8': tensor([141., 401.]),\n",
       "  'C9': tensor([2., 4.]),\n",
       "  'C10': tensor([ 631., 1574.]),\n",
       "  'C11': tensor([ 113., 1499.]),\n",
       "  'C12': tensor([1406., 2965.]),\n",
       "  'C13': tensor([4., 8.]),\n",
       "  'C14': tensor([400., 198.]),\n",
       "  'C15': tensor([882.,  36.]),\n",
       "  'C16': tensor([11., 26.]),\n",
       "  'C17': tensor([3., 2.]),\n",
       "  'C18': tensor([138.,  75.]),\n",
       "  'C19': tensor([11.,  3.]),\n",
       "  'C20': tensor([ 114., 1255.]),\n",
       "  'C21': tensor([1011., 1711.]),\n",
       "  'C22': tensor([ 113., 1374.]),\n",
       "  'C23': tensor([1209., 1466.]),\n",
       "  'C24': tensor([835.,  38.]),\n",
       "  'C25': tensor([ 2., 32.]),\n",
       "  'C26': tensor([23., 18.])},\n",
       " 'labels': tensor([0, 0])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify all the features in config.yaml to prevent clunky display\n",
    "# we'll need to update vocabulary size for each categorical features\n",
    "# if we were to use a different dataset\n",
    "\n",
    "# for category in ordinal_encoder.categories_:\n",
    "#     print(len(category))\n",
    "with open(\"features_config.yaml\", \"r\") as f_in:\n",
    "    config = yaml.safe_load(f_in)\n",
    "\n",
    "tabular_features_config = config[\"tabular_features_config\"]\n",
    "\n",
    "data_loader = DataLoader(dataset_train, batch_size=2, collate_fn=tabular_collate_fn)\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16f01b",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952971cc",
   "metadata": {},
   "source": [
    "Our model architecture mainly involves: Converting categorical features into a low dimensonal embedding, these embedding outputs are then concatenated with rest of the dense features before feeding them into subsequent feed forward layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd10fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_layers(input_dim: int, mlp_config):\n",
    "    \"\"\"\n",
    "    Construct MLP, a.k.a. Feed forward layers based on input config.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim : \n",
    "        Input dimension for the first layer.\n",
    "\n",
    "    mlp_config : list of dictionary with mlp spec.\n",
    "        An example is shown below, the only mandatory parameter is hidden size.\n",
    "        ```\n",
    "        [\n",
    "            {\n",
    "                \"hidden_size\": 1024,\n",
    "                \"dropout_p\": 0.1,\n",
    "                \"activation_function\": \"ReLU\",\n",
    "                \"activation_function_kwargs\": {},\n",
    "                \"normalization_function\": \"LayerNorm\"\n",
    "                \"normalization_function_kwargs\": {\"eps\": 1e-05}\n",
    "            }\n",
    "        ]\n",
    "        ```\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nn.Sequential :\n",
    "        Sequential layer converted from input mlp_config. If mlp_config\n",
    "        is None, then this returned value will also be None.\n",
    "\n",
    "    current_dim :\n",
    "        Dimension for the last layer.\n",
    "    \"\"\"\n",
    "    if mlp_config is None:\n",
    "        return None, input_dim\n",
    "\n",
    "    layers = []\n",
    "    current_dim = input_dim\n",
    "    for config in mlp_config:\n",
    "        hidden_size = config[\"hidden_size\"]\n",
    "        dropout_p = config.get(\"dropout_p\", 0.0)\n",
    "        activation_function = config.get(\"activation_function\")\n",
    "        activation_function_kwargs = config.get(\"activation_function_kwargs\", {})\n",
    "        normalization_function = config.get(\"normalization_function\")\n",
    "        normalization_function_kwargs = config.get(\"normalization_function_kwargs\", {})\n",
    "\n",
    "        linear = nn.Linear(current_dim, hidden_size)\n",
    "        layers.append(linear)\n",
    "\n",
    "        if normalization_function:\n",
    "            normalization = getattr(nn, normalization_function)(hidden_size, **normalization_function_kwargs)\n",
    "            layers.append(normalization)\n",
    "\n",
    "        if activation_function:\n",
    "            activation = getattr(nn, activation_function)(**activation_function_kwargs)\n",
    "            layers.append(activation)\n",
    "\n",
    "        dropout = nn.Dropout(p=dropout_p)\n",
    "        layers.append(dropout)\n",
    "        current_dim = hidden_size\n",
    "\n",
    "    return nn.Sequential(*layers), current_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fb506-cb39-4c8c-8ade-d6c1d16c7d47",
   "metadata": {},
   "source": [
    "The next code block involves defining a config and model class following huggingface transformer's class structure [[3]](https://huggingface.co/docs/transformers/custom_models). This allows us to leverage its Trainer class for training and evaluating our models instead of writing custom training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a29232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModelConfig(PretrainedConfig):\n",
    "\n",
    "    model_type = \"tabular\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tabular_features_config=None,\n",
    "        mlp_config=None,\n",
    "        num_labels=2,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tabular_features_config = tabular_features_config\n",
    "        self.mlp_config = mlp_config\n",
    "        self.num_labels = num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d1616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(PreTrainedModel):\n",
    "\n",
    "    config_class = TabularModelConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.embeddings, output_dim = self.init_tabular_parameters(config.tabular_features_config)\n",
    "        self.mlp, output_dim = get_mlp_layers(output_dim, config.mlp_config)\n",
    "        self.head = nn.Linear(output_dim, config.num_labels)\n",
    "\n",
    "    def forward(self, tabular_inputs, labels=None):\n",
    "        concatenated_inputs = self.concatenate_tabular_inputs(\n",
    "            tabular_inputs,\n",
    "            self.config.tabular_features_config\n",
    "        )\n",
    "        mlp_outputs = self.mlp(concatenated_inputs)\n",
    "        logits = self.head(mlp_outputs)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        # at the bare minimum, we need to return loss as well as logits\n",
    "        # for both training and evaluation\n",
    "        return loss, F.softmax(logits, dim=-1)\n",
    "\n",
    "    def concatenate_tabular_inputs(self, tabular_inputs, tabular_features_config):\n",
    "        numerical_inputs = []\n",
    "        categorical_inputs = []\n",
    "        for name, config in tabular_features_config.items():\n",
    "            if config[\"dtype\"] == \"categorical\":\n",
    "                feature_name = f\"{name}_embedding\"\n",
    "                share_embedding = config.get(\"share_embedding\")\n",
    "                if share_embedding:\n",
    "                    feature_name = f\"{share_embedding}_embedding\"\n",
    "\n",
    "                embedding = self.embeddings[feature_name]\n",
    "                features = tabular_inputs[name].type(torch.long)\n",
    "                embed = embedding(features)\n",
    "                categorical_inputs.append(embed)\n",
    "            elif config[\"dtype\"] == \"numerical\":\n",
    "                features = tabular_inputs[name].type(torch.float32)\n",
    "                if len(features.shape) == 1:\n",
    "                    features = features.unsqueeze(dim=1)\n",
    "\n",
    "                numerical_inputs.append(features)\n",
    "\n",
    "        if len(numerical_inputs) > 0:\n",
    "            numerical_inputs = torch.cat(numerical_inputs, dim=-1)\n",
    "\n",
    "        categorical_inputs.append(numerical_inputs)\n",
    "        concatenated_inputs = torch.cat(categorical_inputs, dim=-1)\n",
    "        return concatenated_inputs\n",
    "\n",
    "    def init_tabular_parameters(self, tabular_features_config):\n",
    "        embeddings = {}\n",
    "        output_dim = 0\n",
    "        for name, config in tabular_features_config.items():\n",
    "            if config[\"dtype\"] == \"categorical\":\n",
    "                feature_name = f\"{name}_embedding\"\n",
    "                # create new embedding layer for categorical features if share_embedding is None\n",
    "                share_embedding = config.get(\"share_embedding\")\n",
    "                if share_embedding:\n",
    "                    share_embedding_config = tabular_features_config[share_embedding]\n",
    "                    embedding_size = share_embedding_config[\"embedding_size\"]\n",
    "                else:\n",
    "                    embedding_size = config[\"embedding_size\"]\n",
    "                    embedding = nn.Embedding(config[\"vocab_size\"], embedding_size)\n",
    "                    embeddings[feature_name] = embedding\n",
    "\n",
    "                output_dim += embedding_size\n",
    "            elif config[\"dtype\"] == \"numerical\":\n",
    "                output_dim += 1\n",
    "\n",
    "        return nn.ModuleDict(embeddings), output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4dcc615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters:  51308904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeddings): ModuleDict(\n",
       "    (C1_embedding): Embedding(179728, 64)\n",
       "    (C2_embedding): Embedding(12325, 32)\n",
       "    (C3_embedding): Embedding(11780, 32)\n",
       "    (C4_embedding): Embedding(4156, 32)\n",
       "    (C5_embedding): Embedding(10576, 32)\n",
       "    (C6_embedding): Embedding(3, 3)\n",
       "    (C7_embedding): Embedding(5850, 32)\n",
       "    (C8_embedding): Embedding(1139, 32)\n",
       "    (C9_embedding): Embedding(38, 16)\n",
       "    (C10_embedding): Embedding(136421, 64)\n",
       "    (C11_embedding): Embedding(33820, 32)\n",
       "    (C12_embedding): Embedding(34916, 32)\n",
       "    (C13_embedding): Embedding(10, 10)\n",
       "    (C14_embedding): Embedding(1841, 32)\n",
       "    (C15_embedding): Embedding(5445, 32)\n",
       "    (C16_embedding): Embedding(56, 16)\n",
       "    (C17_embedding): Embedding(4, 4)\n",
       "    (C18_embedding): Embedding(615, 32)\n",
       "    (C19_embedding): Embedding(14, 14)\n",
       "    (C20_embedding): Embedding(187780, 64)\n",
       "    (C21_embedding): Embedding(80020, 32)\n",
       "    (C22_embedding): Embedding(165496, 64)\n",
       "    (C23_embedding): Embedding(29741, 9)\n",
       "    (C24_embedding): Embedding(7693, 32)\n",
       "    (C25_embedding): Embedding(54, 16)\n",
       "    (C26_embedding): Embedding(33, 16)\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=789, out_features=1024, bias=True)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.1, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (head): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_config = [\n",
    "    {\n",
    "        \"hidden_size\": 1024,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    },\n",
    "    {\n",
    "        \"hidden_size\": 512,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    },\n",
    "    {\n",
    "        \"hidden_size\": 256,\n",
    "        \"dropout_p\": 0.1,\n",
    "        \"activation_function\": \"ReLU\",\n",
    "        \"normalization_function\": \"LayerNorm\"\n",
    "    }\n",
    "]\n",
    "config = TabularModelConfig(tabular_features_config, mlp_config)\n",
    "model = TabularModel(config)\n",
    "print(\"# of parameters: \", model.num_parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b3f3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4340, grad_fn=<NllLossBackward0>),\n",
       " tensor([[0.6561, 0.3439],\n",
       "         [0.6399, 0.3601]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a quick test on a sample batch to ensure model forward pass runs\n",
    "output = model(**batch)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff41488-9cb4-41fa-9f0c-a5b16495bbc9",
   "metadata": {},
   "source": [
    "Rest of the code block defines boilerplate code for leveraging huggingface transformer's Trainer, as well as defining a `compute_metrics` function for calculating standard binary classification related metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b6b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds, round_digits: int = 3):\n",
    "    y_pred, y_true = eval_preds\n",
    "    y_score = y_pred[:, 1]\n",
    "\n",
    "    log_loss = round(metrics.log_loss(y_true, y_score), round_digits)\n",
    "    roc_auc = round(metrics.roc_auc_score(y_true, y_score), round_digits)\n",
    "    pr_auc = round(metrics.average_precision_score(y_true, y_score), round_digits)\n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'log_loss': log_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd200158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9045' max='9045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9045/9045 19:43, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Pr Auc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.133939</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>75.662400</td>\n",
       "      <td>1321.660000</td>\n",
       "      <td>165.208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.146196</td>\n",
       "      <td>0.718000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>75.984300</td>\n",
       "      <td>1316.062000</td>\n",
       "      <td>164.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.193100</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>0.137163</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>75.452500</td>\n",
       "      <td>1325.337000</td>\n",
       "      <td>165.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.131718</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>75.892400</td>\n",
       "      <td>1317.654000</td>\n",
       "      <td>164.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>74.677300</td>\n",
       "      <td>1339.095000</td>\n",
       "      <td>167.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.128440</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>73.770400</td>\n",
       "      <td>1355.558000</td>\n",
       "      <td>169.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.131577</td>\n",
       "      <td>0.721000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>76.291500</td>\n",
       "      <td>1310.761000</td>\n",
       "      <td>163.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.134822</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>74.252700</td>\n",
       "      <td>1346.752000</td>\n",
       "      <td>168.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.127899</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>73.945800</td>\n",
       "      <td>1352.341000</td>\n",
       "      <td>169.043000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"DISABLE_MLFLOW_INTEGRATION\"] = \"TRUE\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"tabular\",\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=0.001,\n",
    "    per_device_train_batch_size=128,\n",
    "    gradient_accumulation_steps=2,\n",
    "    fp16=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    do_train=True,\n",
    "    # we are collecting all tabular features into a single entry\n",
    "    # tabular_inputs during collate function, this is to prevent\n",
    "    # huggingface trainer from removing these features while processing\n",
    "    # our dataset\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    data_collator=tabular_collate_fn,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# for this dataset, Roc-AUC typically falls in the range of 0.725 - 0.727\n",
    "train_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e99ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[0.99899954, 0.0010005 ],\n",
       "       [0.99010193, 0.00989806],\n",
       "       [0.9948001 , 0.00519988],\n",
       "       ...,\n",
       "       [0.9937588 , 0.00624126],\n",
       "       [0.83815056, 0.16184942],\n",
       "       [0.869991  , 0.13000904]], dtype=float32), label_ids=array([0, 0, 0, ..., 0, 0, 0]), metrics={'test_loss': 0.13327662646770477, 'test_roc_auc': 0.719, 'test_pr_auc': 0.085, 'test_log_loss': 0.133, 'test_runtime': 73.7289, 'test_samples_per_second': 1356.321, 'test_steps_per_second': 169.54})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also leverage .predict for quickly performing batch prediction on a given\n",
    "# input dataset\n",
    "prediction_output = trainer.predict(dataset_test)\n",
    "prediction_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f770c-3ead-4ec7-9dd8-c301b74f6b87",
   "metadata": {},
   "source": [
    "## End Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ce3bf-18d3-459d-a676-b3ed54e70cde",
   "metadata": {},
   "source": [
    "In this post, we walked through a baseline workflow for training tabular datasets using deep neural networks in PyTorch. Many works have cited the success of applying deep neural networks as part of their core recommendation stack, e.g. Youtube Recommendation [[5]](https://dl.acm.org/doi/10.1145/2959100.2959190) or Airbnb Search [[6]](https://arxiv.org/abs/1810.09591) [[7]](https://arxiv.org/abs/2002.05515). Apart from making the model bigger/deeper for improving performance, we'll briefly touch upon some of their key learnings to conclude this article.\n",
    "\n",
    "**Heterogeneous Signals**\n",
    "\n",
    "Compared to matrix factorization based algorithms in collaborative filtering, it's easier to add diverse set of signals into the model.\n",
    "\n",
    "For instance, in the context of Youtube recommendation:\n",
    "\n",
    "- Recommendation system particularly benefit from specialized features that capture historical behavior. This includes user's previous interaction with the item, how many videos has the user watched from a specific channel? Time since the user last watched a video on a particular topic. Apart from numerical features that are hand crafted, we can also include user's watch or search history as variable length sequence and have it mapped into a dense embedding representation.\n",
    "- In a retrieval + ranking staged system, candidate generation information can be propagated into ranking phase as features. e.g. which sources nominated a candidate and its assigned score.\n",
    "- Categorical variables' embedding can be shared. e.g. a single video id embedding can be leveraged across various features (impression video id, last video id watched by the user, seed video id for the recommendation).\n",
    "- While popular tree based models are invariant to scaling of individual features, neural networks are quite sensitive to them. Therefore, Normalizing continuous features is a must. Normalization can be done via Min/Max scaling, log-transformation, or standard normalization.\n",
    "- Recommendation system often exhibit some form of bias towards the past, as they are trained using prior data. For Youtube, adding a content's age on a platform allows the model to represent a video's time dependent behavior.\n",
    "\n",
    "e.g. For Airbnb search:\n",
    "\n",
    "- Domain knowledge proves to be valuable in feature normalization. e.g. When dealing with geo location represented by latitude and longitude, instead of using the raw coordinates, we can calculate the offset from map's center displayed to the user. This allows the model to learn distance based global properties rather than specifics of individual geography. For learning local geography, a new categorical feature is created by taking city specified in the query, and the level 12 S2 cell for a listing. A hashing function then maps these two values (city and S2 cells) into an integer. For example, given the query \"San Francisco\" and a listing near the Embarcadero (S2 cell 539058204), hashing {\"San Francisco\", 539058204} -> 71829521 creates this categorical feature.\n",
    "- Position bias is also a notable topic in literature. This bias emerges when historical logs are used for training subsequent models. Introducing position as a feature while regularizing by dropout was proposed as strategies for mitigating this bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15e766",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe6eea",
   "metadata": {},
   "source": [
    "- [[1]](https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/) Criteo 1TB Click Logs dataset\n",
    "- [[2]](https://www.kaggle.com/competitions/criteo-display-ad-challenge/data) Kaggle Competition - Display Advertising Challenge\n",
    "- [[3]](https://huggingface.co/docs/transformers/custom_models) Transformers Doc - Sharing custom models\n",
    "- [[4]](https://www.fast.ai/posts/2018-04-29-categorical-embeddings.html) Blog: An Introduction to Deep Learning for Tabular Data\n",
    "- [[5]](https://dl.acm.org/doi/10.1145/2959100.2959190) Paul Covington, Jay Adams, Emre Sargin - Deep Neural Networks for YouTube Recommendations (2016)\n",
    "- [[6]](https://arxiv.org/abs/1810.09591) Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tao Xu, Shulin Yang, Huizhong Duan, Qing Zhang, Nick Barrow-Williams, Bradley C. Turnbull, Brendan M. Collins, Thomas Legrand - Applying Deep Learning To Airbnb Search (2018)\n",
    "- [[7]](https://arxiv.org/abs/2002.05515) Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tyler Sax, Lanbo Zhang, Aamir Mansawala, Shulin Yang, Bradley Turnbull, Junshuo Liao - Improving Deep Learning For Airbnb Search (2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
